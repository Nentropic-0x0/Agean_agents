# 🚀 Agean Agents Alliteration 🌌

### LangGraph-based Agent Graph for Accurate, Timely Analysis of Data 🌍🛰️

<img src="public/github.svg" alt="Github" width="10%" />
<img src="public/langchain.svg" alt="Langchain" width="10%" />
<img src="public/pytorch.svg" alt="Pytorch" width="10%" />
<img src="public/rust.svg" alt="Rust" width="10%" />

## Overview

**Agean Agents Alliteration** is an early-stage project focused on creating a sophisticated, LangGraph-powered agent system designed for **accurate and timely data analysis**. By leveraging advanced graph-based agents, we aim to optimize the inflow and processing of data while maintaining high levels of accuracy and field consistency. 🌐🤖

This project is a direct relative of the **Orion platform** 🛠️, built in Rust, which handles the inflow of information, standardizes data, and ensures consistent field processing across agents. This platform prioritizes deterministic programmatic methods over stochastic models to reduce load on human threat hunters, while ensuring JSON stability and ECS schema coercion. 🔧🛡️

## Key Components

- **Orion Platform** 🛰️: 
  - Written in Rust, this platform manages data inflow 🚀, ensuring normalization and standardization of incoming data, and seamlessly passing insights between units. 
  - Focuses on **JSON stability** and **field consistency** to prevent confusion among agents, ensuring reliable and predictable agent behavior. 📊

- **LangGraph-based Agent Framework** 🌌: 
  - The agent system is built on **LangGraph** 🧠, a framework that allows for context-aware, graph-based interactions between agents. 
  - Agents process data deterministically, using **LangSmith** for tracing and validation, inspired by the **Jet Propulsion Laboratory's virtual turtle project** 🐢🛠️.

- **Lightweight ELK Stack** 🌟: 
  - Integrated with a test **ELK Stack environment** 🖥️, supporting log ingestion, real-time data analysis, and visualizations. 
  - **ECS schema coercion** ensures compatibility and standardization within the stack, making sure that data formats are consistent across the system. 🌍

- **Deterministic over Stochastic Models** 🧩:
  - While curious about the potential of cutting-edge 3-8 billion parameter models, the project deliberately minimizes reliance on stochastic methods for basic data processing. 
  - Instead, we focus on **deterministic, programmatic methods** to streamline the pipeline, reduce noise, and increase clarity in threat analysis. ⚙️🛡️

## Project Inspiration 🌠

This project draws inspiration from **NASA's Jet Propulsion Laboratory** 🛸 and their **virtual turtle** project, which validates the use of **LangGraph** for controlling robotic systems. Our goal is to adapt their approach for real-world data processing and threat detection, ensuring our agents can operate autonomously with minimal human intervention. 👾🛰️

## Long-Term Vision 🛸

Our vision is to build a system where human threat hunters are needed only for critical decision-making, while sophisticated agents handle the bulk of data processing and analysis. 🚀🌌 The less we rely on random outputs from large models and the more we trust deterministic, programmed agents, the closer we get to a production-ready solution. 🧠🔒

By continuously refining the system, integrating new models when needed, and validating results through deterministic frameworks, we believe **Agean Agents Alliteration** will become a powerful tool for data-driven threat detection and analysis. 🌍🛡️

#### -- Nentropy
**nen@nentropic.dev**